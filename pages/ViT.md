- [[flomo]]
  #+flomo_tag: ViT
- *架构简洁描述：*
  
  *知识点：*
  * 位置编码是可学习的，而不是预先给定的
  
  * 使用1维的位置编码，而不是高级的2D-aware，因为并没有观察到替换后明显的性能增加
  
  
  * CNN中的归纳偏置包括locality（二维的邻居结构）和平移不变性，但是ViT中只有MLP层是具有局部性和平移不变性的
  
  * ViT中的自注意力层是全局的，所以不是归纳偏置！
  
  * ViT中对二维邻居结构的归纳偏置利用得很稀疏，只用到了两处：将图片分成不同的Patch块；在fine-tune阶段调整不同分辨率大小图片的位置编码；
  
  
  * CNN和ViT的混合架构：CNN架构提取特征图，然后在特征图上提取Patch再进行ViT。（备注：此时提取的Patch大小可以是1*1的）
  
  
  * 预训练和细调注意事项：通常细调的数据集上图片的分辨率更高；预训练时需要将原本的分类头移除掉，然后增加一个线性转换层，将特征维度转换为下游任务的分类数
  
  
  *创新点：*
  * 没有像之前的工作那样把与图像具体的归纳偏好直接融入到架构当中去，仅仅是增加了提取图像Patch块的步骤
  
  * 利用了在大规模数据集上预训练的方法
  
  * 在许多图像分类数据集上能达到或者超过sota方法，但是预训练成本低
  
  
  *缺点或者限制：*
  * 不能应用于像检测和分割这样的计算机视觉任务
  
  * 需要继续探索自监督的预训练方法，目前自监督和大规模监督预训练方法还有较大的差距
	- ![image](https://flomo.oss-cn-shanghai.aliyuncs.com/file/2022-02-14/370015/713a132dcc597b9dcf38e7d2eb65cca4.png?OSSAccessKeyId=LTAI4G9PcaGksWVKCPrE1TVL&Expires=1677137972&Signature=ba7gvfpEVeN4BfpbLyfkNsOBsBM%3D)
	  #+isImg: true