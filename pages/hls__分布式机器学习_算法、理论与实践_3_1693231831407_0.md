file:: [分布式机器学习_算法、理论与实践_3_1693231831407_0.pdf](../assets/分布式机器学习_算法、理论与实践_3_1693231831407_0.pdf)
file-path:: ../assets/分布式机器学习_算法、理论与实践_3_1693231831407_0.pdf

-
-
- 这里，参数服务器并不 是指某一台特定的实体服务器，而是对应一个可伸缩的服务器组。通常，一组模型的参数会通过一定的规则哈希到不同的实体服务器中进行存储
  ls-type:: annotation
  hl-page:: 59
  hl-color:: green
  id:: 64ecabf4-fc35-468f-9817-15f36c885385
- 依据模型的不同，数据表有不同的具体形式：可以是简单向 量 ，也可以是矩阵、张量或晗希表；可以是稠密的形式，也可以是稀疏的形式
  ls-type:: annotation
  hl-page:: 59
  hl-color:: green
  id:: 64ecadb1-cecb-4a39-aa8d-8c3cd0b492b5
- A凹的具体形式与用户的访问模式有关。比如在深度神 经网络的学习 过程中，往往 是 处理少量样本后就会对所有参数进行更新，这种情况下用户通常调用对全部参数操作的接口来完成。在逻辑回归的学习过程中，处理少量样本后，通常只产生对模型参数的稀疏更新，这种情况下参数的请求和 l更新则可以调用处理稀疏参数的接口，从而降低传输的数据量，减少网络带宽的占用，提高交互的效率
  ls-type:: annotation
  hl-page:: 62
  hl-color:: green
  id:: 64ecb21f-07e7-4da5-9631-f678dd2afc08
- 此外，客户端也缓存本地 工 作节点 产 生的模型更新，这样做可以将本地的更新做 一 些汇总后再通过网络 一 并发送 。 当 模型有很 多 稀疏更新时，如果 每产 生 一 些更新就发送出去，网络包太细碎，会严重 影 H 向网络的通信效率 。 通过汇总打包后再发送，可以大大减少网络请求的次数，提高交 互 的 效率
  ls-type:: annotation
  hl-page:: 63
  hl-color:: green
  id:: 64ecb2c4-4b10-4c02-9f96-466543b996ab
- 在接受 参数服务器端传来的最新参数时，客户端 也 需要将来自不同服务器的信息 汇总
  ls-type:: annotation
  hl-page:: 63
  hl-color:: green
  id:: 64ecb561-b884-42ef-ad9a-96948c7cc4f5
- Master 是 一 个执行引 擎 ， 拿 到数据流图的信息之 后 ， 会 结合数据流固和计算资源的情况将具体的计算分配给工作节点来完成
  ls-type:: annotation
  hl-page:: 66
  hl-color:: green
  id:: 64ecbb98-090f-415f-96af-fb1306536238
- aster 将计算算子发送给 Wo r ker, Worker 负责用其管理的设备来执行这些算子并返回结果给 Master 。
  ls-type:: annotation
  hl-page:: 66
  hl-color:: green
  id:: 64ecbbb1-1bd6-4a5a-b73f-d11395330353
- TensorF low 对于 Client- Master- Worker 有很灵活的配置方式，既可以让它们工作在单个节 点中， 也可以让它们 工作在分布式 的环 境中 利用 多 机 多卡进行今 训练 。 一 般在单机环境下，这 三 者在同一个进程 当 巾；而在分布式环境下，它们会用远程过程调用（ RPC )的方式连接起来（参见图 l I. I0 ） 
  ls-type:: annotation
  hl-page:: 66
  hl-color:: green
  id:: 64ecbc46-7b23-4aba-8702-9e251e18559f