- # Trial1
  collapsed:: true
	- 不加transformer+ 两分支模型部分融合  结构  =》 不行
	- ![image.png](../assets/image_1655215736021_0.png)
- # Trial2
  collapsed:: true
	- 加transformer+ 预训练的两分支模型部分融合  结构  =》 不行
	- ![image.png](../assets/image_1655269411565_0.png){:height 653, :width 1059}
- # Trial3
  collapsed:: true
	- net35 + deep_latent
	- ![image.png](../assets/image_1655271651284_0.png)
	- ![image.png](../assets/image_1655274121655_0.png)
- # Chaos
  collapsed:: true
	- ![image.png](../assets/image_1655275235003_0.png)
	- ![image.png](../assets/image_1655278980866_0.png)
	- ![image.png](../assets/image_1655279139800_0.png)
	- ![image.png](../assets/image_1655296205328_0.png)![image.png](../assets/image_1655296657787_0.png)
- # 思考
  collapsed:: true
	- 我感觉问题是　从模型获得的特征应该还是占据主要地位的　而额外特征没有那么重要　所以的话我觉得前者可以设置的维度为１０００　后者可以设置的维度为１００或者５００之类的
	- 有没有可能加权得到两个维度不一样长的特征呢？
	- 主要是觉得使用ｔｆｒｍ融合得到的两个特征应该很大程度上是相近的了，所以融合后除了拼接相加还有什么其他融合方式呢？
	- 想把多个不同模型融合，但是太难训练了，该怎么办呢？
	- 注入随机性到底要怎么弄呢？
	- 就是总感觉这个ｆｃ层太孤立了
	- 前是用ｔｒａｎｓｆｏｒｍｅｒ对两个特征分支进行相关性融合的，怎么让它的合并结果变成一个呢
		-
		- 就是我现在没有想到以一种非常合理的方式去进行融合
			- 这种方式希望参数尽可能的少
			- 然后的话能够起到融合的效果
			- 这里一共就只有４层
			- 所以最多可以融合３层
			-
			-
			- 分配验证集数据
			- 首先把原来训练测试的代码改一下，增加验证集
			- 原来的模型可以再次测试一下
			- 现在用刚才设想的方式实验一下吧
			-
- # 重新弄数据
  collapsed:: true
	-
	- ![image.png](../assets/image_1655384527089_0.png)
	-
		- ![image.png](../assets/image_1655397451749_0.png)
		- ![image.png](../assets/image_1655397746673_0.png)
	- 我现在就是根本不知道从哪个角度下手去解决出现的问题了
		- 问题是  我保存验证集上val loss最小的点  对应的train acc貌似都没有超过80%的了 而且在对应的测试集上的差异也很大
		- 是数据集上的问题吗？
			- 一是这个数据集划分的问题？用另外一组划分数据测试一下？
			- 二要不要又重新回到原始的428和20张数据的测试集上去？因为感觉这时候不管数据集怎么划分，是不是还是不够涵盖所有的数据类型？
			- 是调参的问题吗？
				- 是不是学习率设置得不恰当，导致没有办法很好的收敛。这个可以从训练集的损失下降   看出来？
					- 损失是一直在不断下降的，感觉学习率设置的有点高了，
			- 我的标签对应关系写的对吗
				- 1对应的肯定是恶性，0对应的肯定是良性，还是反过来？
				- 损失函数的加权前面和后面的权重与标签是什么样的对应关系？
				-
- # 428个数据按照8:1:1划分训练集、验证集和测试集
	- net32的结果：也就是纯resnet50，修改最后一层全链接层 为（2048, 2）
	  collapsed:: true
		- ![image.png](../assets/image_1655437426069_0.png)
	-
	- 使用val acc为指标，resnet50追加fc层的方式，第1个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655440391340_0.png)
	- 使用val acc为指标，resnet50追加fc层的方式，第2个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655441364567_0.png)
	- 使用val acc为指标，resnet50追加fc层的方式，第3个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655441864642_0.png)
	-
	- 使用val acc为指标，resnet50修改fc层的方式，第3个划分的数据集
		- ![image.png](../assets/image_1655442325292_0.png)
	- 使用val acc为指标，resnet50修改fc层的方式，第2个划分的数据集
		- ![image.png](../assets/image_1655442878382_0.png)
	- 使用val acc为指标，resnet50修改fc层的方式，第1个划分的数据集
		- ![image.png](../assets/image_1655443363914_0.png)
	-
	- 可以看到，第一个划分 训练和验证  与  测试的区别非常大，第三个 训练验证 与 测试的区别是最小的
	-
	- 使用val acc的net17，在第一个划分数据集上
		- ![image.png](../assets/image_1655450148426_0.png)
	- 使用val loss的net17，在第一个划分数据集上
		- ![image.png](../assets/image_1655450854719_0.png) 
		  id:: 62ac2a4f-11f8-433e-9730-ca8da92f92fe
	- 感觉还是不对啊，用val loss选择的结果就是训练集和验证集的准确率都不高，测试集的准确率也不高，但比val acc要好一些，这只是一个巧合吧？
	-
	- 100次训练迭代，val acc为判断标准，去掉了resnet50的一层
		- ![image.png](../assets/image_1655452557286_0.png)
	- 100次训练迭代，val acc为判断标准，去掉了resnet50的一层：1024 500    500 2  第一个数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655452954637_0.png)
	- 100次训练迭代，val acc为判断标准，去掉了resnet50的一层：1024 500    500 2 第三个数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655453404169_0.png)
- # 428按照9:1划分训练集和验证集，33作为测试集
  collapsed:: true
	- 划分结果：
	  collapsed:: true
		- ![image.png](../assets/image_1655465398797_0.png)
	- resnet2
		- ![image.png](../assets/image_1655456597413_0.png)
	- resnet1
		- ![image.png](../assets/image_1655457134273_0.png)
	- net32_plus
		- ![image.png](../assets/image_1655459821634_0.png)
	- resnet3
		- ![image.png](../assets/image_1655466955181_0.png)
	- densenet1
		- ![image.png](../assets/image_1655468616079_0.png)
	-
	- 分析1：
		- 两层fc的参数量太大了，但是目前我只是试验了
			- 倒数最后一层（2048,1000）（1000,2）
			- 倒数第二层 (1024, 500)  (500,2)
		- 所以，能不能再把参数改小一点实验一下呢？
	- 分析2：
		- 去掉resnet50的一个残差块，效果不好
	- 分析3：
		- densenet121参数大，只使用一个fc的方式，结果也不好
	- 计划：
		- 因为resnet50的fc默认输出维度是1000，所以肯定不能在这个的基础上使用注意力融合机制了
		- 先实验一下resnet34，resntet18、resnet101的效果
			- resnet34 ResNet4
				- ![image.png](../assets/image_1655471175059_0.png)
			- resnet101 ResNet6
			  collapsed:: true
				-
		- 因为参数量大，所以我得首先把resnet50进行预训练，然后再和我们的模型进行结合
			- 2048 * 2   可是不管转化成哪个维度（100,500）都要比2048 * 2的参数量大，而且刚才已经体验过（2048，1000）的预训练在训练集和验证集上还可以，但是在测试集上不是特别行
			- 这样吧  我实验一下 （2048,100） （100,2），看看效果如何
				- ![image.png](../assets/image_1655472104123_0.png)
				- 测试集上不太行
			- 倒数第一和倒数第二层平均池化结果相连
			  collapsed:: true
				- ![image.png](../assets/image_1655474348870_0.png)
				- 测试集不太行
			-
		- Net32Plus加上deep latent
			- 10 10
				- ![image.png](../assets/image_1655476242945_0.png)
			- 10 50
				- ![image.png](../assets/image_1655477075362_0.png)
			- 10 100
				- ![image.png](../assets/image_1655477919431_0.png)
		- net17
		  collapsed:: true
			- ![image.png](../assets/image_1655481760882_0.png)
	- 分析4：
		- 主要现在设想很多，但是感觉每种设想都没有那么巧妙，而且设计得也比较复杂
		- 1,10,13,15,18,19,20
			- 40 - 7 = 33
			-
		- resnet18
			- ![image.png](../assets/image_1655528425432_0.png)
			- ![image.png](../assets/image_1655534705389_0.png)
	-
	-
	- drop_last、batch_size都会影响每次迭代对应的结果，但是每次随机shuffle并不会（也就是不需要给生成器设置固定的随机种子了）
	- 开始的随机种子也会影响每次迭代的结果，设置种子为0和10是不一样的
	-
	- 因为之前没有去注意到这些差别，导致相同模型的结果是不可重现的，而且我发现在我这个测试集上的差异相对来讲还是很大的，我觉得是因为测试集数据太小了。
	-
	-
	- 所以现在的问题是：不好验证自己的模型是不是比其他模型更好，万一换一下种子、batch_size本轮比其他结果好的模型现在不比其他模型好了 怎么办，这样对于模型好坏的判断就没有多大意义了。而且我只有看到有80%的才觉得有超过的可能性。我现在在这个数据集上试了自己的模型创新点，根本就不行啊
	-
	- 现在就固定所有的，不用管其他的了，就在这个基础上来比较模型。
	- 在resnet18上用一下我的模型吧
	-
	- resnet5
		- ![image.png](../assets/image_1655551251463_0.png)
	- 加上fc注意力
		- ![image.png](../assets/image_1655553763529_0.png)
	-
		- ![image.png](../assets/image_1655554440153_0.png)
		-
	-
		- ![image.png](../assets/image_1655554929411_0.png)
	-
		- ![image.png](../assets/image_1655555527375_0.png)
	-
	- ![image.png](../assets/image_1655556274427_0.png)
	-
	-
	-
	- ![image.png](../assets/image_1655559936429_0.png)
	-
	- ![image.png](../assets/image_1655564417200_0.png)
-
-
- 不需要extra升高维度之后的
- ![image.png](../assets/image_1655566313610_0.png)
- 忘记这个结果的一些重要结论了，我应该把模型和名字写在一排
- ![image.png](../assets/image_1655641925530_0.png)
- 冻结resnet部分进行训练
	- ![image.png](../assets/image_1655646002831_0.png)
-
- resnet50的结果
-
-
- ![image.png](../assets/image_1655651525866_0.png)
- ![image.png](../assets/image_1655654487701_0.png)
-
-
- ![image.png](../assets/image_1655870186469_0.png)
-
- ![image.png](../assets/image_1655872229582_0.png)
-
-
- ![image.png](../assets/image_1655903450957_0.png)
- ![image.png](../assets/image_1655903696749_0.png)
- ![image.png](../assets/image_1655903879116_0.png)
-
-
- ![image.png](../assets/image_1655907849322_0.png){:height 681, :width 1104}
-
- ![image.png](../assets/image_1655954897347_0.png)
-
- ![image.png](../assets/image_1655970305494_0.png)
-
- ![image.png](../assets/image_1655972800853_0.png)
- ![image.png](../assets/image_1656042190464_0.png)
-
-
-
- # 创新
- 直接使用额外特征再增加全连接层转化的方式
- 比较三种方式的结果
- 一是两层fc，但是中间不加relu
	- ![image.png](../assets/image_1655644220572_0.png)
- 二是两层fc，但是中间增加relu
	- ![image.png](../assets/image_1655644761431_0.png)
- 三是将fc的维度从32改为16，64,128,256,512,1024等试一下
	- 64
		- ![image.png](../assets/image_1655644525722_0.png)
			-
	- 128
		- ![image.png](../assets/image_1655645206513_0.png)
	- 512
		- ![image.png](../assets/image_1655644930753_0.png)
	- 16
		- ![image.png](../assets/image_1655645383357_0.png)
- 现在就是说一是需要再增加一些创新点，二是要对这个结果再做一些验证。
- 今天晚上就把所有的实验给弄完吧
- 然后论文也要写得差不多，没有那么难，也没啥好失望的
-
- 验证的话：在那三个不同划分的数据集上试验一下；在35张图片上做一下测试；固定一下两个训练好的模型实验一下；
	- 使用新设计的损失函数设计一下；
	- 我觉得难点在哪里呢，我觉得可以设计一个融合各种信息的模块，但是不大幅增加参数量
	- 如果对于不同维度，可不可以统一转化到一个中间维度，然后还是使用相同的方法来操作
	- 我觉得把多尺度再实验一下吧
	-
- 我觉得这里的融合机制始终是有欠缺的，就是说对于给定的任何长度、任何数量的特征
	- 这里的缺陷是每一个特征都用的是相同的权重，所以这是不太合理的，因为一个特征向量可能很有用，另一个特征向量可能很没用，但是有用特征向量里的每一个值并不是比没用特征向量里的每一个值都有用，所以权重这样解码效果好可能是一个巧合
	- 这两个向量的特征为啥要两两位置对应相加，感觉这个很没有道理，因为即便是进行预训练，学到的fc对最终分类有用，也不能说明其特征信息是两两对应的
	- 将每个位置的特征值转化为长度为16的特征向量，然后所有的进行加权求和
		- 参数量太大了，除了固定的16维特征，单个特征值都要转化为16维（可以使用同样的线性转化？）
		- 高维转向低维一般是增加信息密度，低维转向高维一般是为了散化特征
		- 【5,32，1】 【1,2】 =》【5，32, 2】
		- 【5,32,2】【5,32,2】=》【5，32，2,2】【2,1】=》【5,32,2,1】=》【5,32,2】
		- 【5,32,0】 * 【5,32】+ 【5,32,1】 * 【5,32】=》 【5,32】
	- 在最简化的模型上添加关于均衡化后的图片、最后一层不使用平均池化
	- 最后一层的通道维度太高了，导致根本没有办法充分学习
	- 均衡化的效果也不好
- ![image.png](../assets/image_1656076261017_0.png)
  id:: 62b5a772-7074-4f92-a693-ed9093f8bbd0
- ![image.png](../assets/image_1656081047925_0.png)
- ![image.png](../assets/image_1656081364682_0.png)
- ![image.png](../assets/image_1656087090142_0.png)
-
-
-
- 对比的模型：
	- AlexNet
	- Vgg
	- 手工提取的特征  机器学习和深度学习
	- swin-transformer
- 消融实验
	- 纯resnet18
	- 纯densenet121
	- 纯resnet18 + 纯densenet121 都预训练   + 融合模块
	- 纯resnet18 + 纯densenet121 都不预训练   + 融合模块
	- 纯resnet18 预训练 + 纯densenet121 不预训练   + 融合模块
	- 纯resnet18 不预训练 + 纯densenet121 预训练   + 融合模块
- 讨论
	- 融合的两个模型必须都具有较好的效果 融合后效果才可能更好
	- 三个及以上模型的融合存在很大难度（不管是不是固定其中的一部分不训练）
	- 没法用在特征图的融合之上（因为参数量过大）
	- GRAD-CAM分析始终无法分类正确的图片
	- 模型参数量的分析
- 附录：
	- resnet18和densenet121的详细结构
-
-
- ![image.png](../assets/image_1656319562684_0.png)
- ![image.png](../assets/image_1656377637788_0.png)
-