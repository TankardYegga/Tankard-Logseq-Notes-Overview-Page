title:: mit/6.824

- Introduction:
  collapsed:: true
	- 分布式系统是什么呢？
	  collapsed:: true
		- multiple networked cooperating computers
	- 主要使用场景，可以举例吗？
	  collapsed:: true
		- ![image.png](../assets/image_1687421174924_0.png)
		- 协调完成服务器、客户端和数据中心这三者的工作
		- 比如说ZOOM应用
	- 为什么要使用分布式系统？或者说，为什么分布式系统会变得流行起来？
	  collapsed:: true
		- Connect [[$red]]==physical==ly separated machines => allow data sharing
			- 当我和你的两台机器连接到同一台电脑时，我们可以分享数据、共享文件、共享屏幕、共享计算基础设施，即能够允许一系列的协作可能性
		- Increase capacity through [[$red]]==parallelism==
			- MapReduce是一个重要的例子
			- 在同一个时间段内有很多的Zoom Session在进行
		- [[$red]]==Tolerate faults==
			- 当一个机器或者部分损坏时，不会影响到另外一个机器或者部分，比如存储可以始终分发
			- 容错能力保证了整个系统的可用性
		- Achieve [[$red]]==security== by physical separation / isolation
			- 比如如果你有一个管理顾客密码的服务，所以通常会把它对外的接口设计得非常狭窄
		- 四个重要原因中第二个和第三个是最重要的
	- 分布式系统的Historical Context大概是什么样的？
	  collapsed:: true
		- 1980s年代的local area network
			- 比如MIT的校园网络、连接像Athena集群一样的工作站 (Athena Clusters (亚瑟纳集群) 是谷歌开发的一种分布式计算框架，主要用于数据分析和大规模数据处理)
			- AFS（Andrew File System）是一种分布式文件系统也是在那时发明出来
			- 那时候的主要应用只有DNS和Email系统
		- The rise of Data Centers along with big websites (1990s or early 1990s)
			- web search: 大量的数据进行indexing不能放在一个电脑上
			- shopping: 有大量的用户
			- MapReduce的论文也是在这个时期出来的
		- Cloud Computing (mid late 2000s)
			- 这个过程随着云计算的出现而加速了
			- 将数据和计算移动到数据中心
		- Current state: active
	- 分布式系统的Challenge有哪些？
	  collapsed:: true
		- 两个主要的挑战为：
			- many concurrent parts
				- 并行的计算机数目太多，导致难以推断和理解整个运行的过程
			- must deal with partial failure
		- 这两个挑战导致的问题是：
			- 高并发度和部分出错导致系统的复杂度越来越高，比如系统的一个部分可能认为系统的另外一个部分故障了，但是实际可能不是的，实际可能的是有一个网络划分(network partition)，被划分的系统两边分别保持计算，分别与一部分client进行交互，甚至两边交互的这部分client是完全一样的，因为client可以与系统两边都发生交互，而系统的这两边并不发生交互，这个问题被称作Split Brain Syndrome（大脑分裂综合征）,  这使得design distributed system和protocol statistical system变得复杂；
		- 最后一个挑战是：
			- tricky to realize the performance benefits that in principle are possible with distributed system
				- 也就是在给定数量的机器下来实现high throughput和throughput scaling并没有那么简单直接
	- 为什么要学习这门课？
	  collapsed:: true
		- ![image.png](../assets/image_1687424771020_0.png)
		- hands-on指的是特别的编程体验
	- 怎么学习这门课？
	  collapsed:: true
		- ![image.png](../assets/image_1687425363498_0.png)
		- ![image.png](../assets/image_1687429390407_0.png)
			- 网络系统和分布式系统存在交叉，关于通信的知识主要在MIT6.829中学习到
			- 存储指的是key value存储系统 或者  文件系统
		- ![image.png](../assets/image_1687430828856_0.png)
			- 可恢复性指的是直接重启故障的机器后继续保持可用性，而不是修复系统，因为修复系统必须要将一台一台的机器全部关闭最终导致系统服务不可用
			- 可用性的关键技术是：replication
			- 可恢复性的关键技术是：logging or transactions (durable storage)
			- 一致性希望分布式系统的性能 和 sequential machine尽可能保持一致
			- 不一致性有很多不同的contract，比如最终一致性，关键在于对于Performance的要求不同
			- Performance和Fault tolerance和Consistency是相互矛盾的，为了实现一致性，则需要不同机器之间进行通信，这可能会降低性能；而为了实现容错，则不得不把数据从一台机器复制到其他台机器，而如果把数据写入可持久存储的话，其开销也是非常昂贵的，这会消耗性能。所以，通常会牺牲部分一致性或者部分容错性来提升性能
			- Performance实际包含两个方面：
				- 一个是Throughput, 这个可以通过增加更多的机器来实现
				- 另外一个是low latency,  比如disk不能百分百处理等导致处理用户请求需要很久，
			- 第四个topic是Implementation, 主要是concurrency和RPC
			-
			-
	- MapReduce的历史context是什么？
	  collapsed:: true
		- ![image.png](../assets/image_1687432251142_0.png)
		- Mapeduce方法包含两个部分：
			- 一是map方法和reduce方法，都是functional or stateless function，方法内都是sequential code
			  collapsed:: true
				- Functional function 和 Stateless function 都是程序中的两种函数类型，具体含义如下：
				- Functional function 是指在程序中定义时只参考了输入和输出之间的关系，它不会改变程序的状态或任何外部变量，也没有任何副作用。这种函数通常被称为纯函数，因为它们只关注给定的输入及其返回的输出。由于纯函数不会对程序的状态造成任何影响，因此它们通常易于调试和测试，并可以提高程序的可读性和可维护性。
				- Stateless function 是指在程序中定义时不保留任何状态信息，只根据其输入来计算输出。它们不依赖于任何外部环境或变量，并且不会对程序的状态造成任何影响。这种函数通常用于函数式编程，它们的目标是简单、干净且易于测试的代码。
				- 总之，无论是 Functional function 还是 Stateless function，它们都面向纯粹的函数计算，不依赖外部状态，而是根据输入计算输出。唯一的区别在于前者特别强调不会产生副作用，后者不会保留任何状态信息。
			- 二是处理distributedness，需要解决load balancing、运行缓慢的机器、crash的机器等，使得写map和reduce方法的程序员不用关心这些
		- mapreduce并不是general purposed的？
			- 对，因为需要自己根据case来写对应的map和reduce方法
			- 比如你要写一个key value的服务，将不能使用MapReduce这个库，因为这个库假定了一个特定的计算模型，我们要应用程序必须要fit in这个计算模型，其适用于做一些网页的大数据分析，需要大量计算来处理这些大量的数据，并且基于这些数据来计算值
			-
	- 关于MapReduce的一些问题？
		- 同样的一个Map Task有可能执行两次吗？同样的一个Reduce Task也可能执行两次吗？
		- Map Reduce当中的master可以fail吗？为什么？
		- 一个Map Worker对应的机器上是只执行一个map function还是说可以执行多个map function？
		- 当一个Map Worker对应的机器crash了，要怎么做呢？
- RPCs and threads:
  collapsed:: true
	- 为什么使用Go而不是用C++？
		- C++处理垃圾回收非常麻烦，而多线程应用中需要判断某个对象什么时候不再被任何一个线程使用了
		- C++的语法过于复杂
	- 为什么需要使用线程？
		- I/O  Concurrency
		- Parallelism
			- 充分利用一台机器上的所有核/CPU
		- Convenience
			- 一些程序会需要在后台运行，周期性地运行然后休眠
			- the overhead is worthy ?
				- yes
	- asynchronous program和vent driving program的区别？
	  collapsed:: true
		- Asynchronous programming and event-driven programming are both ways of handling concurrency in software development, but they are not the same thing.
		- Asynchronous programming is a programming paradigm where tasks are executed concurrently without blocking the main thread. This means that a program can execute multiple tasks at the same time, without waiting for one task to complete before starting the next one. Asynchronous programming is typically used in situations where a program needs to perform I/O operations, such as reading from a file or making a network request, without blocking the main thread.
		- Event-driven programming, on the other hand, is a programming paradigm where the flow of the program is determined by events that occur, rather than by a sequential order of execution. In an event-driven program, the program waits for events to occur, such as mouse clicks or keyboard presses, and then responds to those events. Event-driven programming is often used in graphical user interfaces, where the program needs to respond to user input in real-time.
		- While there is some overlap between asynchronous programming and event-driven programming, they are not the same thing. Asynchronous programming is a way of handling concurrency, while event-driven programming is a way of structuring the flow of a program based on events.
		- 线程比事件驱动更容易，因为它只需要写直接的流程控制代码：计算、发送信息、等待响应，
			- 而后者它需要把无论什么活动都分割成很多小的片段，这些小的代码片段会不时地被相应的事件驱动循环在某个时刻激活，因此编程来说会更加困难；此外如果在事件驱动编程下如果你想要获得并发，将无法获得CPU的并行，比如你要写一个保持32核都忙碌的繁忙的服务器，一个单一的循环不是一个自然的方式去利用超过一个核；
			- 通常这种方式的开销会比线程稍微小一点，为什么呢？
				- 因为当多线程的数量超过1000时，管理线程的开销就开始变大，包括维持每个线程的状态、决定下次该执行哪一个线程
		- 进程是由操作系统来控制的，与具体使用什么语言无关
	- 当一个context发生切换时，所有的线程都发生了对应的切换吗？
	  collapsed:: true
		- 假如你有一台单核的机器，你在上面运行了多个进程，OS会给不同的进程time slicing来进行来回切换，所以当硬件计时结束时，CPU从一个进程拿走，被放置到另外一个进程之上；context切换时只有操作系统知道的线程会进行切换
		- go cleverly multiplex as many go routines on top of single operating system threads to reduce overhead
			- 这句话的意思是，在单个操作系统线程上巧妙地多路复用多个Go协程，以减少开销。
			- 在Go语言中，协程（goroutine）是一种轻量级的线程，可以在单个线程上同时运行多个协程，而不需要为每个协程分配一个单独的线程。这种设计可以提高程序的并发性能，但也会带来一些开销，例如上下文切换、协程调度等。
			- 因此，这句话的意思是，为了减少这些开销，可以在单个操作系统线程上巧妙地多路复用（multiplex）多个Go协程，即在单个线程上同时运行多个协程，从而减少上下文切换和调度的开销。这种方式可以提高程序的并发性能，同时也可以减少系统资源的使用
		- 这是一个两阶段的调度，先决定哪个大线程去运行，然后go决定哪一个协程在那个进程中运行
		-
	- 线程有哪些缺点？
	  collapsed:: true
		- Race conditions:
		  collapsed:: true
			- 虽然线程之间可以共享内存或者缓存，但是可能会存在很多的bug，比如下面这个共享变量的例子
			  collapsed:: true
				- ![image.png](../assets/image_1687762038539_0.png)
					- 一般来说存储原语是原子的，而INCREMENT原语非常有可能不是原子的
					- 不同线程运行同一段代码的过程，可以被称作RACE，因为第二个线程可能在第一个写入更新后的X之前或者之后就Load X的值了
			- 怎么解决Race Conditions呢？
			  collapsed:: true
				- 有两种解决方法：
					- 一是Avoid Sharing,
						- 这是Go所鼓励的编程风格：鼓励使用channels来communicate变量的值，而不是通过共享内存
					- 二是使用locking使得一组操作序列变成atomic的
						- Go怎么知道哪个变量在上锁，比如是X + Y这种操作？
						  collapsed:: true
							- Go并不知道任何变量和锁的关系，这是由程序员来控制的
						- 锁应该是private的吗？
						  collapsed:: true
							- 数据结构的私有就好像市政规划地图（Zoning Map）内部有一个lock在保护它。这会是一个合理的策略，define a data structure that needs to be locked to have the lock be sort of interior that have each of the data structure methods be responsible for acquiring that lock and the user the data structure may never know：
							  collapsed:: true
								- This sentence means to create a data structure that requires locking, where the lock is an internal mechanism and each method within the data structure is responsible for acquiring the lock before proceeding with its task. The user who interacts with the data structure may not be aware of the existence of the lock as it is handled automatically by the data structure's methods. This approach helps to ensure thread safety and prevent data corruption from multiple threads accessing the same data simultaneously.
							- 唯一的崩溃点是：
								- 如果一个编程人员知道这个数据将从来不会被分享，他们可能会失望他们为了不需要被locked的东西而付出了额外的锁的开销
								- if there's any inter data structure of dependencies，so we have two data structures  each with locks and they may use each other and then there's risks of cycles and deadlocks
									- 通常解决deadlock的方法是requires lifting the locks out of the implementations up in the calling code（需要将锁从实现层面提升到调用代码层面）
							- 隐藏锁是一个good idea，但不总是
						- Go语言中有一个RaceDetector，大多数的lab会鼓励你使用dash race flag来运行go，这不会捕获每个可能的Race，但是它已经能很好地识别races了，所以默认情况下你应该开启race detector enabled来运行go。
		- Coordination：一个线程必须等待另外一个线程完成某些事
		  collapsed:: true
			- Go中的channel不仅用来交流值，也可以同时用来coordinate
			- 通过条件变量
		- DeadLocks
		  collapsed:: true
			- 在Go中最trivial的出现死锁的情况是：
				- 有一个单线程，此时它block了，等待其他的线程从它的channel里面读取数据，但是很明显并没有其他的channel存在
				- Go将会捕捉到这种情况，并且会报出一个razor runtime error
			-
	- Go语言解决并发问题的两个Plan是什么？
	  collapsed:: true
		- ![image.png](../assets/image_1687772074136_0.png)
		-
	- Go中的条件变量可以被看作是什么？
	  collapsed:: true
		- 可以看作是协调进程之间的coordination原语(primitive)，尤其是当使用lock来保护共享状态(shared state) 的时候
		-
		-
	- Web Crawler项目的目标是什么呢？
	  collapsed:: true
		- ![image.png](../assets/image_1687853212490_0.png)
			- 第二个目标一次性获取到URL，是在说correctness的要求
		-
	- Go当中的RPC是如何工作的？
	  collapsed:: true
		- ![image.png](../assets/image_1687879945764_0.png)
			- marshal 和 unmarshal 是序列化和反序列化的过程。序列化是将数据结构或对象转换为字节流的过程，以便将其从一个应用程序发送到另一个应用程序或存储在磁盘上。反序列化是将字节流转换回原始数据结构或对象的过程
			- 序列化和反序列化的方法可能有所不同，但通常采用比较常见的方式，比如 JSON、XML、Protobuf、MessagePack 等
			- 这些stub使得远程过程调用和regular/local procedure call的效果差异不大，并且这些stub通常都是自动生成的
	- RPC的failures有哪些可能的语义呢？
	  collapsed:: true
		- ![image.png](../assets/image_1687914194519_0.png)
			- 至少一次：
				- 如果server fail了，那么client应该做什么呢？此时当client第一次向crashed的server发送请求时，必然得不到响应，所以会time out，然后client就会自动进行重试，直到server的函数调用至少执行了一次
				- 这种至少一次的rpc系统的downside是同一个操作可能会被执行很多次，这并不适用于许多应用
			- 最多一次：
				- 对应的服务端的请求要么执行1次，要么就不执行，不会超过1次
				- 这典型是由filtering duplicates来实现的
				- 服务器端可能同时接受到两个request，或许这时的网络就像一个临时请愿 (temporary petition) 且服务器接受到两个requests，此时的服务器必须进行管理：先检测a recent request, 但是并不会execute两次
			- 刚刚好一次（理想情况下）：
				- 因为这是normal情况下的procedure call会展现的
				- 但这通常非常难去进行管理或者说安排arrange,  要求你不得不维持磁盘上的状态, 这个维持操作是昂贵的。在实践中，只有很少的RPC系统是exactly once的
	- Go语言中的rpc的failures的语义是哪一种呢？
	  collapsed:: true
		- 是at most once
		- 通过tcp channel来发起调用，tcp channel将会保证没有duplicates。应用程序可能会进行重试，但将是应用程序的责任来处理duplication和failed message的问题
		- rpc和pc的区别是通过failure时的goal来体现的
		-
	-
	-
- GFS：
  collapsed:: true
	- 课程计划是什么？
	  collapsed:: true
		- ![image.png](../assets/image_1687937958780_0.png)
		- ![image.png](../assets/image_1687938329759_0.png)
		-
	- 为什么涉及存储系统会很难？
	  collapsed:: true
		- 存储系统有high performance的要求 =》需要有many servers
			- shared data across multiple servers
		- many servers意味着会有 ==> constant faults
		- constant faults => fault tolerance design =》replication
			- 在存储系统通常的方式是replication，也就是将数据在多个disk上进行复制
		- replication =》potential inconsistency
		- strong consistency protocol =》low performance caused by sending messages
			- 不是发送的消息有多大，而是协议的一部分是对可持久存储进行读或者写，而这个操作是开销昂贵的
			-
			-
	- 分布式存储系统中一致性的两大hazard是什么？
	  collapsed:: true
		- 一是一致性问题
		  collapsed:: true
			- 什么是ideal consistency？
			  collapsed:: true
				- 通过一个具体的执行案例，明确合理的值是什么、不合理的值是什么来定义什么是consistency
					- ![image.png](../assets/image_1687940308288_0.png)
						- C3读取的结果可能是1或者2，这取决于C1和C2并发执行的相对顺序
						- C4读取的结果和C3完全保持一致
						-
				-
		- 二是failure问题
		  collapsed:: true
			- 对于复制没有任何约束时，是最坏的复制策略，也可以视作no protocol
				- ![image.png](../assets/image_1687940892468_0.png)
	- GFS的case study主要学习些什么？
	  collapsed:: true
		- ![image.png](../assets/image_1687943468070_0.png)
	- GFS 有哪些特点？
	  collapsed:: true
		- ![image.png](../assets/image_1687944433857_0.png)
-