- # Trial1
  collapsed:: true
	- 不加transformer+ 两分支模型部分融合  结构  =》 不行
	- ![image.png](../assets/image_1655215736021_0.png)
- # Trial2
  collapsed:: true
	- 加transformer+ 预训练的两分支模型部分融合  结构  =》 不行
	- ![image.png](../assets/image_1655269411565_0.png){:height 653, :width 1059}
- # Trial3
  collapsed:: true
	- net35 + deep_latent
	- ![image.png](../assets/image_1655271651284_0.png)
	- ![image.png](../assets/image_1655274121655_0.png)
- # Chaos
  collapsed:: true
	- ![image.png](../assets/image_1655275235003_0.png)
	- ![image.png](../assets/image_1655278980866_0.png)
	- ![image.png](../assets/image_1655279139800_0.png)
	- ![image.png](../assets/image_1655296205328_0.png)![image.png](../assets/image_1655296657787_0.png)
- # 思考
  collapsed:: true
	- 我感觉问题是　从模型获得的特征应该还是占据主要地位的　而额外特征没有那么重要　所以的话我觉得前者可以设置的维度为１０００　后者可以设置的维度为１００或者５００之类的
	- 有没有可能加权得到两个维度不一样长的特征呢？
	- 主要是觉得使用ｔｆｒｍ融合得到的两个特征应该很大程度上是相近的了，所以融合后除了拼接相加还有什么其他融合方式呢？
	- 想把多个不同模型融合，但是太难训练了，该怎么办呢？
	- 注入随机性到底要怎么弄呢？
	- 就是总感觉这个ｆｃ层太孤立了
	- 前是用ｔｒａｎｓｆｏｒｍｅｒ对两个特征分支进行相关性融合的，怎么让它的合并结果变成一个呢
		-
		- 就是我现在没有想到以一种非常合理的方式去进行融合
			- 这种方式希望参数尽可能的少
			- 然后的话能够起到融合的效果
			- 这里一共就只有４层
			- 所以最多可以融合３层
			-
			-
			- 分配验证集数据
			- 首先把原来训练测试的代码改一下，增加验证集
			- 原来的模型可以再次测试一下
			- 现在用刚才设想的方式实验一下吧
			-
- # 重新弄数据
  collapsed:: true
	-
	- ![image.png](../assets/image_1655384527089_0.png)
	-
		- ![image.png](../assets/image_1655397451749_0.png)
		- ![image.png](../assets/image_1655397746673_0.png)
	- 我现在就是根本不知道从哪个角度下手去解决出现的问题了
		- 问题是  我保存验证集上val loss最小的点  对应的train acc貌似都没有超过80%的了 而且在对应的测试集上的差异也很大
		- 是数据集上的问题吗？
			- 一是这个数据集划分的问题？用另外一组划分数据测试一下？
			- 二要不要又重新回到原始的428和20张数据的测试集上去？因为感觉这时候不管数据集怎么划分，是不是还是不够涵盖所有的数据类型？
			- 是调参的问题吗？
				- 是不是学习率设置得不恰当，导致没有办法很好的收敛。这个可以从训练集的损失下降   看出来？
					- 损失是一直在不断下降的，感觉学习率设置的有点高了，
			- 我的标签对应关系写的对吗
				- 1对应的肯定是恶性，0对应的肯定是良性，还是反过来？
				- 损失函数的加权前面和后面的权重与标签是什么样的对应关系？
				-
- # 428个数据按照8:1:1划分训练集、验证集和测试集
	- net32的结果：也就是纯resnet50，修改最后一层全链接层 为（2048, 2）
	  collapsed:: true
		- ![image.png](../assets/image_1655437426069_0.png)
	-
	- 使用val acc为指标，resnet50追加fc层的方式，第1个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655440391340_0.png)
	- 使用val acc为指标，resnet50追加fc层的方式，第2个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655441364567_0.png)
	- 使用val acc为指标，resnet50追加fc层的方式，第3个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655441864642_0.png)
	-
	- 使用val acc为指标，resnet50修改fc层的方式，第3个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655442325292_0.png)
	- 使用val acc为指标，resnet50修改fc层的方式，第2个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655442878382_0.png)
	- 使用val acc为指标，resnet50修改fc层的方式，第1个划分的数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655443363914_0.png)
	-
	- 可以看到，第一个划分 训练和验证  与  测试的区别非常大，第三个 训练验证 与 测试的区别是最小的
	-
	- 使用val acc的net17，在第一个划分数据集上
	  collapsed:: true
		- ![image.png](../assets/image_1655450148426_0.png)
	- 使用val loss的net17，在第一个划分数据集上
	  collapsed:: true
		- ![image.png](../assets/image_1655450854719_0.png) 
		  id:: 62ac2a4f-11f8-433e-9730-ca8da92f92fe
	- 感觉还是不对啊，用val loss选择的结果就是训练集和验证集的准确率都不高，测试集的准确率也不高，但比val acc要好一些，这只是一个巧合吧？
	-
	- 100次训练迭代，val acc为判断标准，去掉了resnet50的一层
	  collapsed:: true
		- ![image.png](../assets/image_1655452557286_0.png)
	- 100次训练迭代，val acc为判断标准，去掉了resnet50的一层：1024 500    500 2  第一个数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655452954637_0.png)
	- 100次训练迭代，val acc为判断标准，去掉了resnet50的一层：1024 500    500 2 第三个数据集
	  collapsed:: true
		- ![image.png](../assets/image_1655453404169_0.png)
- # 428按照9:1划分训练集和验证集，33作为测试集
	- 划分结果：
	  collapsed:: true
		- ![image.png](../assets/image_1655465398797_0.png)
	- resnet2
		- ![image.png](../assets/image_1655456597413_0.png)
	- resnet1
		- ![image.png](../assets/image_1655457134273_0.png)
	- net32_plus
		- ![image.png](../assets/image_1655459821634_0.png)
	- resnet3
		- ![image.png](../assets/image_1655466955181_0.png)
	- densenet1
		- ![image.png](../assets/image_1655468616079_0.png)
	-
	- 分析1：
		- 两层fc的参数量太大了，但是目前我只是试验了
			- 倒数最后一层（2048,1000）（1000,2）
			- 倒数第二层 (1024, 500)  (500,2)
		- 所以，能不能再把参数改小一点实验一下呢？
	- 分析2：
		- 去掉resnet50的一个残差块，效果不好
	- 分析3：
		- densenet121参数大，只使用一个fc的方式，结果也不好
	- 计划：
		- 因为resnet50的fc默认输出维度是1000，所以肯定不能在这个的基础上使用注意力融合机制了
		- 先实验一下resnet34，resntet18、resnet101的效果
			- resnet34 ResNet4
				- ![image.png](../assets/image_1655471175059_0.png)
			- resnet101 ResNet6
			  collapsed:: true
				-
		- 因为参数量大，所以我得首先把resnet50进行预训练，然后再和我们的模型进行结合
			- 2048 * 2   可是不管转化成哪个维度（100,500）都要比2048 * 2的参数量大，而且刚才已经体验过（2048，1000）的预训练在训练集和验证集上还可以，但是在测试集上不是特别行
			- 这样吧  我实验一下 （2048,100） （100,2），看看效果如何
				- ![image.png](../assets/image_1655472104123_0.png)
				- 测试集上不太行
			- 倒数第一和倒数第二层平均池化结果相连
			  collapsed:: true
				- ![image.png](../assets/image_1655474348870_0.png)
				- 测试集不太行
			-
		- Net32Plus加上deep latent
			- 10 10
				- ![image.png](../assets/image_1655476242945_0.png)
			- 10 50
				- ![image.png](../assets/image_1655477075362_0.png)
			- 10 100
				- ![image.png](../assets/image_1655477919431_0.png)
		- net17
		  collapsed:: true
			- ![image.png](../assets/image_1655481760882_0.png)
	- 分析4：
		- 主要现在设想很多，但是感觉每种设想都没有那么巧妙，而且设计得也比较复杂
		- 1,10,13,15,18,19,20
			- 40 - 7 = 33
			-
		- resnet18
			- ![image.png](../assets/image_1655528425432_0.png)
			- ![image.png](../assets/image_1655534705389_0.png)
	-
	-
	- drop_last、batch_size都会影响每次迭代对应的结果，但是每次随机shuffle并不会（也就是不需要给生成器设置固定的随机种子了）
	- 开始的随机种子也会影响每次迭代的结果，设置种子为0和10是不一样的
	-
	- 因为之前没有去注意到这些差别，导致相同模型的结果是不可重现的，而且我发现在我这个测试集上的差异相对来讲还是很大的，我觉得是因为测试集数据太小了。
	-
	-
	- 所以现在的问题是：不好验证自己的模型是不是比其他模型更好，万一换一下种子、batch_size本轮比其他结果好的模型现在不比其他模型好了 怎么办，这样对于模型好坏的判断就没有多大意义了。而且我只有看到有80%的才觉得有超过的可能性。我现在在这个数据集上试了自己的模型创新点，根本就不行啊
	-
	- 现在就固定所有的，不用管其他的了，就在这个基础上来比较模型。
	- 在resnet18上用一下我的模型吧
	-
	- resnet5
		- ![image.png](../assets/image_1655551251463_0.png)
	- 加上fc注意力
		- ![image.png](../assets/image_1655553763529_0.png)
	-
		- ![image.png](../assets/image_1655554440153_0.png)
		-
	-
		- ![image.png](../assets/image_1655554929411_0.png)
	-
		- ![image.png](../assets/image_1655555527375_0.png)
	-
	- ![image.png](../assets/image_1655556274427_0.png)
	-
	-
	-
	- ![image.png](../assets/image_1655559936429_0.png)
	-
	- ![image.png](../assets/image_1655564417200_0.png)
-
-
- ![image.png](../assets/image_1655566313610_0.png)
-
-