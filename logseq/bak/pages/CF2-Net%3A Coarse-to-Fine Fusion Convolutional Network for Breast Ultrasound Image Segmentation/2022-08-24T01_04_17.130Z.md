title:: CF2-Net: Coarse-to-Fine Fusion Convolutional Network for Breast Ultrasound Image Segmentation

- 论文背景：
	- 基于超声的CAD主要包含图像分割、特征提取和模型重建，其中图像分割会直接影响到诊断的准确性和鲁棒性
	- 主要困难是：
		- 1）图片质量低，包括对比度低、散斑噪声和伪影
		- 2）超声图像中的乳腺肿块具有各种各样的尺寸和形状，并且边缘比较模糊
	- 现有的方法：
		- 1）基于邻居像素或者区域相似性的：需要形状、外观、以及空间位置的先验知识
		- 2）基于模型的方法：使用独特的基于先验或者后验能量函数以及优化算法
		- 1）2）都对于噪声敏感，并且倾向于过分割
		- 4）现有的深度学习：仅仅使用残差连接来连接编码器和解码器之间的信息
- 论文创新点：
	- 【1】将超像素图像和原始图像在通道方向进行连接，一同作为模型的输入，而不是把超像素操作作为模型输出的后处理
		- 使用的是simple linear iterative clustering (SLIC) algorithm
			- SLIC 可以生成紧凑的patch，保持轮廓完整性，为网络提供额外的细节
			- 来自原始图像通道的信息可以指导网络微调分割结果
	- 【2】提出了一种“E”形的融合方式来融合编码器和解码器之间的信息
		- 同一尺度下的编码器提取的特征浅、粗糙，而解码器提取的特征深、细致。提出的融合方法能够去除两种信息之间冗余的部分，实现更紧凑的信息整合。
		- 模块包含四个组成部分：
			- ASPP：
				- 目的：通过多个感受野来同时捕获多种尺寸的乳腺肿块的信息。
				- 过程：
					- 此模块的输入包括同一尺度下来自编码器和解码器输出的两个特征图
					- 这两个特征图分别进行ASPP，得到各自更新后的特征图
			- CFF unit （Cascade Feature Fusion）：
				- 目的：对更新后得到的两个特征图与上一层该模块输出的特征图进行整合
				- 过程：
					- 更新后的两个特征图各自再经过一层1*1的卷积层，然后再进行拼接
					- 上一层该模块的输出图先上采样然后进行2*2空洞卷积
					- 将上述两类特征图进行相加融合，得到融合的特征图
			- Edge Constraint：
				- 目的：利用边缘信息对提取的特征进行约束
				- 过程：
					- 融合特征图经过1 * 1,3 * 3,1 * 1的三次卷积，再与原始的融合特征图进行残差连接。连接后的结果直接输入下一个模块。
					- 融合特征图经过1 * 1,3 * 3的两次卷积后，增加一个额外的分支：这个分支利用1*1的卷积输出边缘的分割结果
			- Tiny Unet:
				- 目的：对增加了边缘约束后的特征图提取更高层次的特征
				- 过程：
					- 使用一层Unet的结构来提取一个
		- 【3】提出了类平衡的损失函数
			- 目的：每张图片中的乳腺肿块尺寸都不太一样，这样背景和肿块这两个类别的像素比例在每张图片中都是不同的，但都是 背景像素总数  远大于 肿块像素总数，所以就分割任务来说，无论是交叉熵损失函数还是dice损失函数，都应该把这两类像素区别开。
			- 过程：
				- ![image.png](../assets/image_1661171810273_0.png)
				- 分割损失使用加权的交叉熵损失和dice损失和。但是这两种损失的任意一种，都将背景像素和肿块像素区别开，分别计算两种像素的权重。
				-
			- 补充：整个模型对Unet FSP 和 EC模块的输出都构建相应的损失，并进行加权，其中EC模块的权重最低。
				- ![image.png](../assets/image_1661171267966_0.png)
			-
			-
			-
			-
		-
		-
		-
- 关于论文模型的疑问：
	- 这里并没有用Fusion Stream Path来替代原有的残差连接，而是增加这样的一条分支？
	- 来自编码器和解码器的特征图在经过ASPP之后在直接相连前，为什么还要各自再进行卷积？
	- 这里不同层级的特征图之间为什么使用相加融合而不是拼接融合？
	- 为什么边缘约束模块要放在与上一层级特征图融合之后，而不是之前？
	- 边缘约束模块看上去只是单纯增加了3层卷积层，为什么可以保证输出的特征图就具有边缘语义？
	- 为什么边缘模块不直接将第二个卷积层的特征图作为边缘预测图，还需要再经过一个卷积层？为什么边缘图的通道数要固定为32？
	- 为什么要设计一个微缩版本的tinyUnet，而不直接使用边缘模块的输出结果？Unet能work的根本原因是？
- 关于改进的思考：
	- 边缘约束模块可以再参考一些其他的论文进行改进，这里的该模块感觉没有那么make sense。
	- 个人理解Unet能work的原因有2点：一是通过残差连接实现上下层级间的信息融合，从而每个像素点对应的特征向量既有局部信息又有全局信息，而分割任务的关键在于获取每个像素点的信息；二是不同层级之间的信息融合时，对应的通道数是相同的，这就使得每个像素上的特征向量是不同深度的信息的一种均匀混合。
		- 所以思路是：
			- 一是增加每个层次信息的丰富程度，设想的是每个层级的编码器后再接一个对应的ASPP，然后将编码器的特征图和ASPP的特征图进行融合；
			- 二是改变不同层次之间融合的方式，未必需要使用级联的解码器层，可以直接在原有的编码器层次上融合，也就是向下和向上的两个分支都可以在同一模块上进行，或者向上向下的分支可以同时进行而不先下后上；
			- 三是在每一层都增加对于信息的引导，或者对于在最后一个输出模块增加。引导模块怎么增加还在思考。
	- 现有的分割损失函数中dce损失描述的是预测和目标间整体上的关系，而交叉熵损失则描述的是预测和目标上每个像素点之间的关系。训练的先后可以使用不同的损失函数吗？
-