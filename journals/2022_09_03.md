- DONE 回去跑步半小时，KEEP打卡
  :LOGBOOK:
  CLOCK: [2022-09-03 Sat 13:20:27]
  CLOCK: [2022-09-03 Sat 13:20:34]--[2022-09-06 Tue 14:51:45] =>  73:31:11
  :END:
- DONE 改完论文终稿 #paper-writing
  collapsed:: true
  :LOGBOOK:
  CLOCK: [2022-09-03 Sat 13:21:39]--[2022-09-08 Thu 21:36:48] =>  128:15:09
  :END:
	- 首先再查找一些TMI的论文
	- 思考哪些地方的描述是多余的
	- 思考哪些地方还需要补充描述
	- 修改错误
		- 比例划分不合适
		- 数据量小
		- 交叉验证中只划分训练集和测试集的话，那么没有验证集的帮助是怎么进行模型选择的呢？
		- 比较小的数据集一般按照6:2:2的比例划分训练、验证和测试，如果这个数据本身分布不够均匀，这样训练集的比例是不是过小了，而使得训练得到的模型本身就不够具有泛化性？为何有些博客也指出可以按照8：1：1的比例来划分数据集呢？
		- In the study, a total of 428 images were collected from the First Affiliated Hospital of Nanjing Medical University between September 2010 and January 2019, of which 218 were labeled as malignant and 210 as benign. All the images met the following four criteria: (1) the detected MCs were scored at the 4th level of BI-RADS; (2) the corresponding patient underwent surgical biopsy with mammographic guidance and had no history of any therapy for breast lesions; (3) MCs were confirmed to be successfully excised by X-Ray photography, and (4) pathological result was the gold standard. By means of random indexing, 428 images were divided into the training set, validation set, and test set in the ratio of 8:1:1 with the proportion of positive and negative labels in each set matching that of the entire sample.
		- According to Fig. 8, the preprocessing steps were carried out in the following order: a) region of interest (ROI) selection, where a rectangle box containing the most obvious calcifications was drawn on each image by a radiologist with more than ten years of clinical experience; b) image cropping, where images were cropped precisely along the border of the ROI; c) image resizing, where all ROIs were scaled to the same size (128 * 128）through bi-linear interpolation; d) calcification segmentation, where discrete wavelet transform and closed operation were used to automatically segment calcification, following which radiologists deleted false positive data points physically.
		- During the training stage, the learning rate was fixed at 0.0008 and the SGD optimizer was adopted with a momentum of 0.9. Cross entropy loss function was utilized in its weighted form, with 0.6 set for the malignant label and 0.4 set for the benign label, because incorrect classifications of malignant cases would cause more severe outcomes. To prevent overfitting, the L2 regularization with a weight decay of 0.001 was also employed. In addition, $c_1$ was set to 32; $w_1$, $w_2$, and $w_3$ were set to 1.0, 1.0, and 1.0, respectively; and $d$ was set to 8.
		- All models were trained for 35 epochs before being terminated. It was also worth noting that the learning rate would be altered slightly based on different models.
		- 关于方法概览，这个前提一词特别僵硬，而且讲完前提之后过渡到整体描述感觉不连贯。对于提出损失函数的作用没有说。
			- 这里一个前提是说要选择哪两个模型去融合，并给出原因；第二个前提就是融合这两个模型需要进行的细微修改。
			- 就是怎么把前提换一种表述方式呢？
				- An overview of the proposed method is depicted in Fig. 3, which revolves around the core technology of model fusion. Before digging deeper into the pipeline's specifics, it is essential to understand two fundamental predefined settings.
				- The first setting determines which of the two models would be fused. After a thorough examination, resnet18 and densenet121 appeared as the most promising candidates. For one reason, resnet18 and densenet121 have the fewest parameters in the resnet and densenet network architectures, respectively (see Fig. 5(a) and Appendix A), and are thus suitable for modeling problems with small sample sizes. For another, the features captured by resnet18 and densenet121 can theoretically complement each other, as the former is good at extracting shallow features and reusing them, while the latter is good at extracting deep features and discovering new ones.
					- Theoretically, the features that resnet18 and densenet121 capture can complement one another, since the former excels at extracting shallow features and recycling features, whereas the latter excels at extracting deep features and discovering new features.
					- The features captured by resnet18 and densenet121 can theoretically complement each other, as the former is good at extracting shallow features and reusing them, while the latter is good at extracting deep features and discovering new ones.
				- The second setting concerns how the two models can be modified to accommodate future fusion. Since we are only interested in the fusion of the models' outputs, we are also only concerned with the Fc (fully connected layer). The conventional structures of resnet18 and densenet121 both consist of a block for feature extraction and a head for classification which is a single Fc.  The length of output vectors from the head equals to the number of categories,  which is obviously insuffcient for effective information fusion due to low density. Consequently, the head is adjusted into two Fcs $fc 1$ and $fc 2$. The $fc 1$ model increases information density by expanding the number of output neurons, the output of which is the point at which the two models fuse. Both models' $fc 2$ have as many output neurons as categories, adding extra outputs for classification. They do not, however, serve as the final prediction but rather enforce constraints when extracting essential features from resnet18 and densenet121.
				- Next, we take a comprehensive look at how our proposed approach works. The proposed model mainly contains three subnets, namely,  the resnet18 branch (green path),  the densenet121 branch (blue path), and the model fusion branch (orange path). Specifically, the resnet18 and densenet121 are used as the backbone for feature extraction, which simultaneously and independently extract their own features from the same image, generating $c_1$-lengthy vectors $m$ and $n$ right after the $fc_1$; the fusion branch works through the similarity-decoding-based weighted fusion mechanism (abbreviated as SDWFM), which fuses the $m$ and $n$ into one vector $fused\_v$ and then pass through the last fc to obtain the final prediction. Notably, the resnet18 path and the densenet121 path both have separate output from $fc 2$ for classification, which is used in conjunction with our proposed multi-output weighted loss function to facilitate model training.
				- Single feature value $m_i$ at each position $i$ $(i = 0, 1, ..., c_1-1)$ of  the vector $m$ is linearly transformed into a $d$-lengthy token $s_i$ using the same matrix $K$ whose shape is $(1,d)$, and the same operation is also performed on each position i of vector $n$ to generate corresponding $d$-lengthy token $t_i$, which can be formulated as:
				- Each position $i$ $(i = 0, 1, ..., c_1-1)$ of  the vector $m$ corresponds to a single feature value $m_i$, which is linearly transformed into a $d$-lengthy token $s_i$ using the same matrix $K$ shaped as $(1,d)$ in this step.
				- The single feature value $m_i$,  corresponding to the $ith$ $(i = 0, 1, ..., c_1-1)$ position of  the vector $m$, is linearly transformed into a $d$-lengthy token $s_i$ using the same matrix $K$ shaped as $(1,d)$ in this step. The same operation is also performed on each position i of vector $n$ to generate corresponding $d$-lengthy token $t_i$.  The process can be formulated as:
				- The vectors $m$ and $n$ have the same length but different feature values $m_i$ and $n_i$ at each position $i$. Obviously, $m_i$ and $n_i$ do not always contain the same type of information, but the loss function discussed later will help. We aim to perform the weighted summation on $m_i$ and $n_i$,  and therefore we need to compute two weights $w^m_i$  which satisfy:
				- A learnable d-lengthy latent embedding L is initialized and shared among every pair $m_i$ and $n_i$  to help the weight calculation.  
				  Dot product is performed both between L and $s_i$ and between $L$ and $t_i$, obtaining $w_{i_1}$ and $w_{i_2}$ first; then $w_{i_1}$ and $w_{i_2}$ are normalized to one through softmax. Thus, we can claim that $L$ decodes the similarity of the feature value at the position i of $m$ and $n$ and and represents it as weights, which is why our fusion mechanism gets its name. Essentially, L reflects the commonality between different feature values.
				- For each position $i$, a weighted summation is performed on $m_i$, and $n_i$ using the obtained $w^m_i$ and $w^n_i$, yielding the ith value of the fused vector $fused_v$, as shown in the formula:
				- Traditionally, accounting for the large parameters introduced by the integration of multiple models, a pre-training strategy has to be enforced, the procedure of which includes three passes of training. Two passes are utilized to pretrain resnet18 and densenet121 as depicted in Figure 5(a), and the final pass is used to train the entire model, which eliminated fc2 from the proposed approach given in Figure 3.
				- To mitigate the proliferation of parametric numbers caused by model integration, a pre-training strategy consisting of three training passes has traditionally been used.
				- Fusion techniques that incorporate info from multiple models are then investigated, but the existing strategies lack interpretability and operational simplicity.
				- $e_0$, $e_1$, and $e_2$ are all dimension values, with $e_0=10$ and $e_2=2$ being fixed.
		- 对于整个概览的描述不生动，读完之后也没有办法形成一个整体感觉。
			-
			-
		-
		-
- [[SourceCodeDissection]]
-
-
-
-